{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A5rTauQV9HY1"
   },
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np; np.random.seed(0)\n",
    "import matplotlib.pyplot as plt; plt.rcParams['font.family'] = 'Malgun Gothic'\n",
    "import seaborn as sns; sns.set_theme(font='Malgun Gothic')\n",
    "\n",
    "import warnings; warnings.filterwarnings(action='ignore')\n",
    "pd.set_option('display.max_rows', 100, 'display.max_columns', 100, 'max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import skew, kurtosis\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.arima_model import ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "# sampling\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import NearMiss\n",
    "\n",
    "# preprocessing\n",
    "from sklearn.impute import SimpleImputer, MissingIndicator, KNNImputer\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler, PowerTransformer, QuantileTransformer\n",
    "from sklearn.preprocessing import Binarizer\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# estimators\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from xgboost import XGBClassifier, XGBRegressor, XGBRFClassifier, XGBRFRegressor\n",
    "from lightgbm import LGBMClassifier, LGBMRegressor\n",
    "from catboost import CatBoostClassifier, CatBoostRegressor\n",
    "\n",
    "# ensemble\n",
    "from sklearn.ensemble import BaggingClassifier, BaggingRegressor, VotingClassifier, VotingRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, GradientBoostingClassifier, GradientBoostingRegressor\n",
    "\n",
    "# clustering\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "\n",
    "# neural\n",
    "import tensorflow as tf; tf.random.set_seed(0)\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, log_loss\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import mean_squared_error, mean_squared_log_error, mean_absolute_error\n",
    "from sklearn.metrics import precision_recall_curve, roc_curve\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "\n",
    "# model_selection\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit, KFold, StratifiedKFold, GridSearchCV\n",
    "\n",
    "# tools\n",
    "import pycaret.classification as pycla\n",
    "import pycaret.regression as pyreg\n",
    "import pycaret.clustering as pyclu\n",
    "import pycaret.utils as pyuti\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions\n",
    "\n",
    "# --------------------------------------------------\n",
    "def check_outliers(X_train, features, rate=1.5):\n",
    "    \n",
    "    dict = {}\n",
    "    \n",
    "    for col in features:\n",
    "        \n",
    "        Q1 = np.percentile(X_train[col], 25) \n",
    "        Q3 = np.percentile(X_train[col], 75) \n",
    "        IQR = Q3 - Q1\n",
    "        \n",
    "        min = Q1 - (rate * IQR)\n",
    "        max = Q3 + (rate * IQR)\n",
    "        \n",
    "        idxs = X_train[(X_train[col] < min) | (X_train[col] > max)].index\n",
    "        \n",
    "        dict[col] = idxs\n",
    "        \n",
    "    return dict\n",
    "# --------------------------------------------------\n",
    "\n",
    "\n",
    "# --------------------------------------------------\n",
    "def scores(y_test, y_pred):\n",
    "    \n",
    "    \"\"\"evaluation scores\"\"\"\n",
    "    \n",
    "    f1        = f1_score         (y_test, y_pred, average='macro')\n",
    "    accuracy  = accuracy_score   (y_test, y_pred, )\n",
    "    precision = precision_score  (y_test, y_pred, average='macro')\n",
    "    recall    = recall_score     (y_test, y_pred, average='macro')\n",
    "    c_matrix  = confusion_matrix (y_test, y_pred, )\n",
    "    \n",
    "    print(\n",
    "          f'accuracy  = {accuracy:.6f},  '\n",
    "          f'f1 score  = {f1:.6f},  \\n'\n",
    "          f'precision = {precision:.6f},  '\n",
    "          f'recall    = {recall:.6f},')\n",
    "    print(c_matrix)\n",
    "    \n",
    "    # plt.figure(figsize=(12, 9))\n",
    "    # plt.title('confusion matrix')\n",
    "    # plt.xlabel('Predict')\n",
    "    # plt.ylabel('Actual')\n",
    "    # sns.heatmap(c_matrix, annot=True, linewidths=1, cmap='Blues', annot_kws={\"size\": 14})\n",
    "    # plt.show()\n",
    "# --------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------\n",
    "def curves(y_test, probas_pred):\n",
    "        \n",
    "    FPRS, TPRS, thresholds = roc_curve(y_test, probas_pred[:, 1])\n",
    " \n",
    "    f, ax = plt.subplots(1, 2, figsize=(16, 6))\n",
    " \n",
    "    # settings\n",
    "    plt.subplot(121)\n",
    "    plt.title('ROC curve')\n",
    "    plt.gray()\n",
    "    plt.xlabel('FPR(1- specificity)')\n",
    "    plt.ylabel('TPR')\n",
    " \n",
    "    # x, y values\n",
    "    plt.plot(FPRS, TPRS, label='ROC', linestyle='solid')\n",
    "    plt.plot([0, 1], [0, 1], label='50%', color='gray', linestyle=':')\n",
    "    plt.legend()\n",
    " \n",
    "    precisions, recalls, thresholds = precision_recall_curve(y_test, probas_pred[:, 1])\n",
    "    f1_scores = 2 * (precisions * recalls) / (precisions + recalls)\n",
    " \n",
    "    plt.subplot(122)\n",
    "    plt.title('precision recall curve')\n",
    "    plt.gray()\n",
    "    plt.xlabel('threshold')\n",
    "    plt.ylabel('scores')\n",
    " \n",
    "    # x, y values\n",
    "    plt.plot(thresholds, precisions[:thresholds.shape[0]], label='precision', linestyle=':')\n",
    "    plt.plot(thresholds, recalls[:thresholds.shape[0]],    label='recall',    linestyle='--')\n",
    "    plt.plot(thresholds, f1_scores[:thresholds.shape[0]],  label='f1',        linestyle='solid')\n",
    "    # valid linestyle = '-', '--', '-.', ':', 'None', ' ', '', 'solid', 'dashed', 'dashdot', 'dotted'\n",
    "    plt.legend()\n",
    " \n",
    "    plt.show()\n",
    "    \n",
    "    print('AUC = ', roc_auc_score(y_test, probas_pred[:, 1]))\n",
    "# --------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "df = pd.DataFrame(iris['data'], columns=iris['feature_names'])\n",
    "df['target'] = iris['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# classification metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitted : LogisticRegression\n",
      "fitted : DecisionTreeClassifier\n",
      "fitted : BaggingClassifier\n",
      "fitted : RandomForestClassifier\n",
      "fitted : GradientBoostingClassifier\n",
      "fitted : XGBClassifier\n",
      "fitted : XGBRFClassifier\n",
      "fitted : LGBMClassifier\n",
      "fitted : CatBoostClassifier\n",
      "--------------------------------------------------\n",
      "classification_models_fitted : list ready\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimator</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>AUC</th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.966583</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.527976</td>\n",
       "      <td>0.455357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.932660</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.966583</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.097348</td>\n",
       "      <td>0.025451</td>\n",
       "      <td>0.420446</td>\n",
       "      <td>0.456755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.966583</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.006405</td>\n",
       "      <td>0.011945</td>\n",
       "      <td>0.267045</td>\n",
       "      <td>0.714605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.932660</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.019696</td>\n",
       "      <td>0.017986</td>\n",
       "      <td>0.592000</td>\n",
       "      <td>0.370319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBRFClassifier</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.932660</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.019255</td>\n",
       "      <td>0.100157</td>\n",
       "      <td>0.386219</td>\n",
       "      <td>0.494370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.966583</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.000</td>\n",
       "      <td>314.000000</td>\n",
       "      <td>313.000000</td>\n",
       "      <td>463.000000</td>\n",
       "      <td>302.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CatBoostClassifier</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.966583</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.000</td>\n",
       "      <td>6.544351</td>\n",
       "      <td>11.203605</td>\n",
       "      <td>35.594006</td>\n",
       "      <td>46.658038</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    estimator  accuracy        F1  precision    recall    AUC  \\\n",
       "0          LogisticRegression  1.000000  1.000000   1.000000  1.000000  1.000   \n",
       "1      DecisionTreeClassifier  0.966667  0.966583   0.969697  0.966667  0.975   \n",
       "2           BaggingClassifier  0.933333  0.932660   0.944444  0.933333  1.000   \n",
       "3      RandomForestClassifier  0.966667  0.966583   0.969697  0.966667  1.000   \n",
       "4  GradientBoostingClassifier  0.966667  0.966583   0.969697  0.966667  1.000   \n",
       "5               XGBClassifier  0.933333  0.932660   0.944444  0.933333  1.000   \n",
       "6             XGBRFClassifier  0.933333  0.932660   0.944444  0.933333  1.000   \n",
       "7              LGBMClassifier  0.966667  0.966583   0.969697  0.966667  1.000   \n",
       "8          CatBoostClassifier  0.966667  0.966583   0.969697  0.966667  1.000   \n",
       "\n",
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \n",
       "0           0.000000          0.000000           0.000000          0.000000  \n",
       "1           0.016667          0.000000           0.527976          0.455357  \n",
       "2           0.000000          0.000000           0.000000          0.000000  \n",
       "3           0.097348          0.025451           0.420446          0.456755  \n",
       "4           0.006405          0.011945           0.267045          0.714605  \n",
       "5           0.019696          0.017986           0.592000          0.370319  \n",
       "6           0.019255          0.100157           0.386219          0.494370  \n",
       "7         314.000000        313.000000         463.000000        302.000000  \n",
       "8           6.544351         11.203605          35.594006         46.658038  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# classification metrics : INPUT TRAIN & TARGET\n",
    "train  = df\n",
    "target = 'target'\n",
    "\n",
    "# split ------------------------------------------------------\n",
    "X = train.drop(target, axis=1)\n",
    "y = train[target]\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, shuffle=True, stratify=y\n",
    ")\n",
    "\n",
    "# model loop -------------------------------------------------\n",
    "classification_result_list = []\n",
    "classification_feature_importance_list = []\n",
    "classification_models = [\n",
    "    LogisticRegression        (),\n",
    "    DecisionTreeClassifier    (),\n",
    "    BaggingClassifier         (),\n",
    "    RandomForestClassifier    (),\n",
    "    GradientBoostingClassifier(),\n",
    "    XGBClassifier             (verbosity=0),\n",
    "    XGBRFClassifier           (verbosity=0),\n",
    "    LGBMClassifier            (),\n",
    "    CatBoostClassifier        (verbose=0),\n",
    "]\n",
    "classification_models_fitted = []\n",
    "\n",
    "for classification_model in classification_models:\n",
    "    \n",
    "    classification_model.fit(X_train, y_train)\n",
    "    \n",
    "    # fitted models appended\n",
    "    classification_models_fitted.append(classification_model)\n",
    "    \n",
    "    y_pred      = classification_model.predict(X_val)\n",
    "    probas_pred = classification_model.predict_proba(X_val)\n",
    "    \n",
    "    # scores -----------------------------------------------------\n",
    "    accuracy  = accuracy_score (y_val, y_pred, )\n",
    "    f1        = f1_score       (y_val, y_pred, average='macro')\n",
    "    precision = precision_score(y_val, y_pred, average='macro')\n",
    "    recall    = recall_score   (y_val, y_pred, average='macro')\n",
    "    \n",
    "    if probas_pred.shape[1] > 2: # multi-label\n",
    "        auc   = roc_auc_score  (y_val, probas_pred, multi_class='ovr')\n",
    "    else:                        # binary-label\n",
    "        auc   = roc_auc_score  (y_val, probas_pred[:, -1],           )\n",
    "    \n",
    "    classification_model_score = [classification_model.__class__.__name__, accuracy, f1, precision, recall, auc]\n",
    "    try:\n",
    "        classification_feature_importance_list.append(classification_model.feature_importances_)\n",
    "    except:\n",
    "        classification_feature_importance_list.append(np.zeros(len(X.columns)))\n",
    "    \n",
    "    classification_result_list.append(classification_model_score)\n",
    "    \n",
    "    print('fitted :', classification_model.__class__.__name__)\n",
    "\n",
    "print('-' * 50)\n",
    "print('classification_models_fitted : list ready')\n",
    "print('-' * 50)\n",
    "\n",
    "# result df\n",
    "classification_df = pd.DataFrame(classification_result_list, columns=['estimator', 'accuracy', 'F1', 'precision', 'recall', 'AUC'])\n",
    "classification_feature_importance_df = pd.DataFrame(classification_feature_importance_list, columns=X.columns)\n",
    "classification_df = pd.concat([classification_df, classification_feature_importance_df], axis=1)\n",
    "classification_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # classification cross_validate : INPUT TRAIN & TARGET\n",
    "# # ============================================================\n",
    "# train_metrics  = iris_df\n",
    "# target_metrics = 'target'\n",
    "# # ============================================================\n",
    "\n",
    "# # split ------------------------------------------------------\n",
    "# X_metrics = train_metrics.drop(target_metrics, axis=1)\n",
    "# y_metrics = train_metrics[target_metrics]\n",
    "\n",
    "# # scoring= --------------------------------------------------\n",
    "# classification_scoring = {\n",
    "#     'accuracy':'accuracy',\n",
    "#     'f1_macro':'f1_macro',\n",
    "#     'precision':'precision_macro',\n",
    "#     'recall':'recall_macro',\n",
    "#     'roc_auc_ovr':'roc_auc_ovr',\n",
    "# }\n",
    "\n",
    "# # cv loop ----------------------------------------------------\n",
    "# classification_cv_list   = []\n",
    "# classification_cv_models = [\n",
    "#     LogisticRegression        (random_state=0),\n",
    "#     DecisionTreeClassifier    (random_state=0),\n",
    "#     BaggingClassifier         (random_state=0),\n",
    "#     RandomForestClassifier    (random_state=0),\n",
    "#     GradientBoostingClassifier(random_state=0),\n",
    "#     XGBClassifier             (random_state=0, verbosity=0),\n",
    "#     XGBRFClassifier           (random_state=0, verbosity=0),\n",
    "#     LGBMClassifier            (random_state=0),\n",
    "#     CatBoostClassifier        (random_state=0, verbose=0),\n",
    "# ]\n",
    "\n",
    "# for classification_cv_model in classification_cv_models:\n",
    "    \n",
    "#     cv_results = cross_validate(\n",
    "#         classification_cv_model,\n",
    "#         X_metrics, y_metrics,\n",
    "#         scoring=classification_scoring,\n",
    "#         cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=0),\n",
    "#         return_estimator=True,\n",
    "#     )\n",
    "\n",
    "#     # scores -----------------------------------------------------\n",
    "#     accuracy  = cv_results['test_accuracy'].mean()\n",
    "#     f1        = cv_results['test_f1_macro'].mean()\n",
    "#     precision = cv_results['test_precision'].mean()\n",
    "#     recall    = cv_results['test_recall'].mean()\n",
    "#     auc       = cv_results['test_roc_auc_ovr'].mean()\n",
    "\n",
    "#     classification_cv_score = [\n",
    "#         classification_cv_model.__class__.__name__, accuracy, f1, precision, recall, auc]\n",
    "\n",
    "#     classification_cv_list.append(classification_cv_score)\n",
    "\n",
    "#     classification_cv_df = pd.DataFrame(\n",
    "#         classification_cv_list, columns=['cv_estimator', 'accuracy', 'F1', 'precision', 'recall', 'AUC'])\n",
    "\n",
    "#     # feature importances-----------------------------------------\n",
    "#     try:\n",
    "        \n",
    "#         cv_fi_list = []\n",
    "#         for idx, estimator in enumerate(cv_results['estimator']):\n",
    "#             fi = pd.DataFrame(estimator.feature_importances_, \n",
    "#                             index=X_metrics.columns, columns=['importance'])\n",
    "#             # fi = fi.sort_values('importance', ascending=False)\n",
    "            \n",
    "#             cv_fi_list.append(estimator.feature_importances_.tolist())\n",
    "#         fi_means = np.array(cv_fi_list).mean(axis=0)\n",
    "        \n",
    "#         fi_df = pd.DataFrame(fi_means, columns=['importance'], index=X_metrics.columns)\n",
    "#         # fi_df = fi_df.sort_values(by='importance', ascending=False)\n",
    "        \n",
    "#         fig, ax = plt.subplots(figsize=(12, 3))\n",
    "#         ax.set_title(classification_cv_model.__class__.__name__)\n",
    "#         sns.set_theme(style='whitegrid')\n",
    "#         sns.set_color_codes('pastel')\n",
    "#         sns.barplot(x='importance', y=X_metrics.columns, data=fi_df)\n",
    "#         plt.show()\n",
    "        \n",
    "#     except:\n",
    "#         pass\n",
    "\n",
    "# classification_cv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # classification GridsearchCV : INPUT TRAIN & TARGET\n",
    "# # ============================================================\n",
    "# train_metrics  = iris_df\n",
    "# target_metrics = 'target'\n",
    "# # ============================================================\n",
    "\n",
    "# # split ------------------------------------------------------\n",
    "# X_metrics = train_metrics.drop(target_metrics, axis=1)\n",
    "# y_metrics = train_metrics[target_metrics]\n",
    "\n",
    "# # param_grid= ------------------------------------------------\n",
    "# hyper_param = {\n",
    "#     'random_state':[0, 1, 2],\n",
    "#     # 'n_estimators':[100],\n",
    "#     # 'min_samples_split':[2],\n",
    "#     # 'min_samples_leaf':[1],\n",
    "# }\n",
    "\n",
    "# # scoring= ---------------------------------------------------\n",
    "# classification_scoring = {\n",
    "#     'accuracy':'accuracy',\n",
    "#     'f1_macro':'f1_macro',\n",
    "#     'precision':'precision_macro',\n",
    "#     'recall':'recall_macro',\n",
    "#     'roc_auc_ovr':'roc_auc_ovr',\n",
    "# }\n",
    "\n",
    "# # GridSearchCV loop ------------------------------------------\n",
    "# classification_gscv_list   = []\n",
    "# classification_gscv_models = [\n",
    "#     LogisticRegression        (random_state=0),\n",
    "#     DecisionTreeClassifier    (random_state=0),\n",
    "#     BaggingClassifier         (random_state=0),\n",
    "#     RandomForestClassifier    (random_state=0),\n",
    "#     GradientBoostingClassifier(random_state=0),\n",
    "#     XGBClassifier             (random_state=0, verbosity=0),\n",
    "#     XGBRFClassifier           (random_state=0, verbosity=0),\n",
    "#     LGBMClassifier            (random_state=0),\n",
    "#     CatBoostClassifier        (random_state=0, verbose=0),\n",
    "# ]\n",
    "\n",
    "# for classification_gscv_model in classification_gscv_models:\n",
    "    \n",
    "#     gscv = GridSearchCV(\n",
    "#         classification_gscv_model,\n",
    "#         param_grid=hyper_param,\n",
    "#         scoring=classification_scoring,\n",
    "#         refit='f1_macro',\n",
    "#         cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=0),\n",
    "#     )\n",
    "    \n",
    "#     gscv.fit(X_metrics, y_metrics)\n",
    "    \n",
    "#     classification_gscv_score = [\n",
    "#         gscv.estimator.__class__.__name__,\n",
    "#         gscv.best_score_,\n",
    "#         gscv.best_params_,]\n",
    "    \n",
    "#     classification_gscv_list.append(classification_gscv_score)\n",
    "\n",
    "# classification_gscv_df = pd.DataFrame(\n",
    "#     classification_gscv_list, columns=['gscv_estimator', 'best_score_', 'best_params_'])\n",
    "# classification_gscv_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# regression metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = datasets.load_boston()\n",
    "df = pd.DataFrame(boston['data'], columns=boston['feature_names'])\n",
    "df['target'] = boston['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0    0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1    0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2    0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3    0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4    0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "..       ...   ...    ...   ...    ...    ...   ...     ...  ...    ...   \n",
       "501  0.06263   0.0  11.93   0.0  0.573  6.593  69.1  2.4786  1.0  273.0   \n",
       "502  0.04527   0.0  11.93   0.0  0.573  6.120  76.7  2.2875  1.0  273.0   \n",
       "503  0.06076   0.0  11.93   0.0  0.573  6.976  91.0  2.1675  1.0  273.0   \n",
       "504  0.10959   0.0  11.93   0.0  0.573  6.794  89.3  2.3889  1.0  273.0   \n",
       "505  0.04741   0.0  11.93   0.0  0.573  6.030  80.8  2.5050  1.0  273.0   \n",
       "\n",
       "     PTRATIO       B  LSTAT  target  \n",
       "0       15.3  396.90   4.98    24.0  \n",
       "1       17.8  396.90   9.14    21.6  \n",
       "2       17.8  392.83   4.03    34.7  \n",
       "3       18.7  394.63   2.94    33.4  \n",
       "4       18.7  396.90   5.33    36.2  \n",
       "..       ...     ...    ...     ...  \n",
       "501     21.0  391.99   9.67    22.4  \n",
       "502     21.0  396.90   9.08    20.6  \n",
       "503     21.0  396.90   5.64    23.9  \n",
       "504     21.0  393.45   6.48    22.0  \n",
       "505     21.0  396.90   7.88    11.9  \n",
       "\n",
       "[506 rows x 14 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitted : LinearRegression\n",
      "fitted : DecisionTreeRegressor\n",
      "fitted : Ridge\n",
      "fitted : Lasso\n",
      "fitted : ElasticNet\n",
      "fitted : BaggingRegressor\n",
      "fitted : RandomForestRegressor\n",
      "fitted : GradientBoostingRegressor\n",
      "fitted : XGBRegressor\n",
      "fitted : XGBRFRegressor\n",
      "fitted : LGBMRegressor\n",
      "fitted : CatBoostRegressor\n",
      "--------------------------------------------------\n",
      "regression_models_fitted : list ready\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimator</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MSLE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>29.260195</td>\n",
       "      <td>5.409269</td>\n",
       "      <td>0.113617</td>\n",
       "      <td>3.668639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>27.184118</td>\n",
       "      <td>5.213839</td>\n",
       "      <td>0.046761</td>\n",
       "      <td>3.407843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>30.144524</td>\n",
       "      <td>5.490403</td>\n",
       "      <td>0.143062</td>\n",
       "      <td>3.711860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>33.914349</td>\n",
       "      <td>5.823603</td>\n",
       "      <td>0.141266</td>\n",
       "      <td>4.022421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>33.297027</td>\n",
       "      <td>5.770358</td>\n",
       "      <td>0.136855</td>\n",
       "      <td>3.993194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BaggingRegressor</td>\n",
       "      <td>15.167646</td>\n",
       "      <td>3.894566</td>\n",
       "      <td>0.025914</td>\n",
       "      <td>2.502843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>14.736465</td>\n",
       "      <td>3.838810</td>\n",
       "      <td>0.025125</td>\n",
       "      <td>2.442088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>10.589213</td>\n",
       "      <td>3.254107</td>\n",
       "      <td>0.021359</td>\n",
       "      <td>2.301365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>10.506135</td>\n",
       "      <td>3.241317</td>\n",
       "      <td>0.019910</td>\n",
       "      <td>2.269540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>XGBRFRegressor</td>\n",
       "      <td>18.464520</td>\n",
       "      <td>4.297036</td>\n",
       "      <td>0.029104</td>\n",
       "      <td>2.712314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>9.839882</td>\n",
       "      <td>3.136859</td>\n",
       "      <td>0.019907</td>\n",
       "      <td>2.171061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CatBoostRegressor</td>\n",
       "      <td>10.899451</td>\n",
       "      <td>3.301432</td>\n",
       "      <td>0.019918</td>\n",
       "      <td>2.119164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    estimator        MSE      RMSE      MSLE       MAE\n",
       "0            LinearRegression  29.260195  5.409269  0.113617  3.668639\n",
       "1       DecisionTreeRegressor  27.184118  5.213839  0.046761  3.407843\n",
       "2                       Ridge  30.144524  5.490403  0.143062  3.711860\n",
       "3                       Lasso  33.914349  5.823603  0.141266  4.022421\n",
       "4                  ElasticNet  33.297027  5.770358  0.136855  3.993194\n",
       "5            BaggingRegressor  15.167646  3.894566  0.025914  2.502843\n",
       "6       RandomForestRegressor  14.736465  3.838810  0.025125  2.442088\n",
       "7   GradientBoostingRegressor  10.589213  3.254107  0.021359  2.301365\n",
       "8                XGBRegressor  10.506135  3.241317  0.019910  2.269540\n",
       "9              XGBRFRegressor  18.464520  4.297036  0.029104  2.712314\n",
       "10              LGBMRegressor   9.839882  3.136859  0.019907  2.171061\n",
       "11          CatBoostRegressor  10.899451  3.301432  0.019918  2.119164"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# regression metrics : INPUT TRAIN & TARGET\n",
    "train  = df\n",
    "target = 'target'\n",
    "\n",
    "# split ------------------------------------------------------\n",
    "X = train.drop(target, axis=1)\n",
    "y = train[target]\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, shuffle=True,\n",
    ")\n",
    "\n",
    "# model loop -------------------------------------------------\n",
    "regression_result_list   = []\n",
    "regression_models = [\n",
    "    LinearRegression         (),\n",
    "    DecisionTreeRegressor    (),\n",
    "    Ridge                    (),\n",
    "    Lasso                    (),\n",
    "    ElasticNet               (),\n",
    "    BaggingRegressor         (),\n",
    "    RandomForestRegressor    (),\n",
    "    GradientBoostingRegressor(),\n",
    "    XGBRegressor             (verbosity=0),\n",
    "    XGBRFRegressor           (verbosity=0),\n",
    "    LGBMRegressor            (),\n",
    "    CatBoostRegressor        (verbose=0),\n",
    "]\n",
    "regression_models_fitted = []\n",
    "\n",
    "for regression_model in regression_models:\n",
    "    \n",
    "    regression_model.fit(X_train, y_train)\n",
    "    \n",
    "    # fitted models appended\n",
    "    regression_models_fitted.append(regression_model)\n",
    "    \n",
    "    y_pred = regression_model.predict(X_val)\n",
    "    \n",
    "    # errors -----------------------------------------------------\n",
    "    mse  = mean_squared_error    (y_val, y_pred)\n",
    "    rmse = mean_squared_error    (y_val, y_pred, squared=False)\n",
    "    msle = mean_squared_log_error(y_val, y_pred)\n",
    "    mae  = mean_absolute_error   (y_val, y_pred)\n",
    "    \n",
    "    regression_model_score = [regression_model.__class__.__name__, mse, rmse, msle, mae]\n",
    "    regression_result_list.append(regression_model_score)\n",
    "    \n",
    "    print('fitted :', regression_model.__class__.__name__)\n",
    "\n",
    "print('-' * 50)\n",
    "print('regression_models_fitted : list ready')\n",
    "print('-' * 50)\n",
    "\n",
    "# result df\n",
    "regression_df = pd.DataFrame(regression_result_list, columns=['estimator', 'MSE', 'RMSE', 'MSLE', 'MAE'])\n",
    "regression_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# regression GridSerachCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "<catboost.core.CatBoostRegressor object at 0x000002A37F1C90D0>\n",
      "3.0490128911729757\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "# regression GridsearchCV : INPUT TRAIN & TARGET\n",
    "train  = df\n",
    "target = 'target'\n",
    "\n",
    "# split ------------------------------------------------------\n",
    "X = train.drop(target, axis=1)\n",
    "y = train[target]\n",
    "\n",
    "# estimator --------------------------------------------------\n",
    "estimator = CatBoostRegressor(verbose=0)\n",
    "\n",
    "# param_grid= ------------------------------------------------\n",
    "hyper_param = {\n",
    "    # 'n_estimators':[100],\n",
    "}\n",
    "\n",
    "# scoring= ---------------------------------------------------\n",
    "regression_scoring = {\n",
    "    # 'MSE':'neg_mean_squared_error',\n",
    "    # 'RMSE':'neg_root_mean_squared_error',\n",
    "    # 'MSLE':'neg_mean_squared_log_error',\n",
    "    'MAE':'neg_mean_absolute_error',\n",
    "}\n",
    "\n",
    "# GridSearchCV -----------------------------------------------\n",
    "\n",
    "gscv = GridSearchCV(\n",
    "    estimator=estimator, param_grid=hyper_param, scoring=regression_scoring, \n",
    "    refit='MAE', \n",
    "    cv=5, \n",
    "    verbose=2, \n",
    ")\n",
    "\n",
    "gscv.fit(X, y)\n",
    "\n",
    "print(gscv.best_estimator_)\n",
    "print(gscv.best_score_ * -1)\n",
    "print(gscv.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Optuna\n",
    "# def objective_xgbr(trial):\n",
    "    \n",
    "#     param = {\n",
    "#         'n_estimators'    :trial.suggest_int       ('n_estimators', 100, 1000),\n",
    "#         'max_depth'       :trial.suggest_int       ('max_depth', 8, 16),\n",
    "#         'min_child_weight':trial.suggest_int       ('min_child_weight', 1, 50),\n",
    "#         'gamma'           :trial.suggest_int       ('gamma', 1, 3),\n",
    "#         'learning_rate'   :0.01,\n",
    "#         'lambda'          :trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
    "#         'alpha'           :trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
    "#         'random_state'    :0\n",
    "#         }\n",
    "    \n",
    "#     xgbr = XGBRegressor(**param)\n",
    "#     xgbr.fit(X_train, y_train, verbose=False)\n",
    "#     y_pred = xgbr.predict(X_test)\n",
    "    \n",
    "#     score = mean_squared_error(y_pred, y_test, squared=False)\n",
    "#     return score\n",
    "\n",
    "# study = optuna.create_study()\n",
    "# study.optimize(objective_xgbr, n_trials=100)\n",
    "# print(study.best_params)\n",
    "\n",
    "# xgbr = XGBRegressor(**study.best_params)\n",
    "# xgbr.fit(X_train, y_train, verbose=False)\n",
    "# y_pred = xgbr.predict(X_test)\n",
    "\n",
    "# score = mean_squared_error(y_pred, y_test, squared=False)\n",
    "# print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # OptunaSearchCV\n",
    "# rfr = RandomForestRegressor(random_state=0)\n",
    "\n",
    "# param_distributions = {\n",
    "#     'n_estimators':     optuna.distributions.IntUniformDistribution(100, 3000), \n",
    "#     'max_depth':        optuna.distributions.IntUniformDistribution(1,   200), \n",
    "#     'min_samples_split':optuna.distributions.IntUniformDistribution(2,   40), \n",
    "#     'min_samples_leaf': optuna.distributions.IntUniformDistribution(1,   20), \n",
    "#     }\n",
    "    \n",
    "    \n",
    "# optuna_search = optuna.integration.OptunaSearchCV(rfr, param_distributions, \n",
    "#                                                   cv=5, n_trials=300, random_state=0, \n",
    "#                                                   scoring='neg_root_mean_squared_error', verbose=1)\n",
    "# optuna_search.fit(X_train_test_met, y_train_test_met)\n",
    "\n",
    "# print(optuna_search.best_score_)\n",
    "# print(optuna_search.best_estimator_)\n",
    "# print(optuna_search.best_params_)\n",
    "\n",
    "# optuna_search.predict(X_sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# deep learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "17164ff5f922defefa3fdd6afe0c064ec3948eda8922a4bbab17a59b9b0232dc"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
