{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "national-embassy",
   "metadata": {},
   "source": [
    "<img src='./img/logo.png'>\n",
    "* ref : https://wikidocs.net/31698,  WikiDoc "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "northern-yellow",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 거리 기반 유사도(similarity)\n",
    "* 유클리드 거리(euclidean distance)\n",
    "* 맨해튼 거리(Manhattan distance)\n",
    "* 마할라노비스 거리 (Mahalanobis distance)\n",
    "* 코사인 유사도(cosine similarity)\n",
    "* 문장/문서 간 거리\n",
    "* 군집(집합) 간 거리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "registered-regression",
   "metadata": {},
   "source": [
    "## 유클리드 거리(euclidean distance)\n",
    "### 좌표 상의 거리 구하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recognized-threat",
   "metadata": {},
   "source": [
    "<img src='./img/img5.png' width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stunning-trauma",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 범주형 데이터에 대한 좌표 거리 구하기\n",
    "* get_dummy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "anonymous-greek",
   "metadata": {},
   "source": [
    "<img src='./img/img6.png' width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interior-logic",
   "metadata": {},
   "source": [
    "## 맨해튼 거리(Manhattan distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demonstrated-dollar",
   "metadata": {},
   "source": [
    "<img src='./img/img7.png' width=150>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accredited-bryan",
   "metadata": {},
   "source": [
    "## 마할라노비스 거리 (Mahalanobis distance) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caring-avenue",
   "metadata": {},
   "source": [
    "<img src='./img/img8.png'  width=\"200\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bottom-strength",
   "metadata": {},
   "source": [
    "## 문장 간의 거리 구하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "owned-income",
   "metadata": {},
   "source": [
    "<img src='./img/img9.png'  width=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decimal-height",
   "metadata": {},
   "source": [
    "## 문서 사이의 거리 구하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tight-texture",
   "metadata": {},
   "source": [
    "<img src='./img/img10.png'  width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "operating-silver",
   "metadata": {},
   "source": [
    "## 군집(집합) 간의 거리 구하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "constitutional-characterization",
   "metadata": {},
   "source": [
    "<img src='./img/img11.png'  width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interested-variance",
   "metadata": {},
   "source": [
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "external-communications",
   "metadata": {},
   "source": [
    "# 문장/문서 유사도(Vector Similarity)\n",
    "* 각 문서의 단어들을 어떤 방법으로 수치화하여 표현했는지(DTM, Word2Vec 등)\n",
    "* 문서 간의 단어들의 차이를 어떤 방법(유클리드 거리, 코사인 유사도 등)으로 계산했는지\n",
    "* ref : https://www.kernix.com/blog/similarity-measure-of-textual-documents_p12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "breeding-uganda",
   "metadata": {},
   "source": [
    "<img src='https://www.kernix.com/doc/articles/overview.svg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "martial-aircraft",
   "metadata": {},
   "source": [
    "## 카운트 기반의 단어 표현(Count based word Representation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "after-allen",
   "metadata": {},
   "source": [
    "### Bag of Words(BoW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "martial-legislation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install konlpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "after-curtis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['정부', '가', '발표', '하는', '물가상승률', '과', '소비자', '가', '느끼는', '물가상승률', '은', '다르다']\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Okt\n",
    "import re\n",
    "okt = Okt()\n",
    "\n",
    "token = re.sub(\"\\.\",\"\",\"정부가 발표하는 물가상승률과 소비자가 느끼는 물가상승률은 다르다.\")\n",
    "token = okt.morphs(token)\n",
    "print(token)\n",
    "  \n",
    "word2index = {}\n",
    "bow = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broken-grocery",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 불용언처리 (english)\n",
    "* 사용자 지정\n",
    "* CountVectorizer에서 지원\n",
    "* NLTK에서 지원 :  https://www.nltk.org/data.html\n",
    "* stopwords 다운 압축풀어 venv/nltk_data/corpora/stopwords에 넣기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "elegant-kitty",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stopwords.words('english')[:10]\n",
    "\n",
    "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "modified-testing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 1 1]]\n",
      "{'family': 1, 'important': 2, 'thing': 4, 'it': 3, 'everything': 0}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "text = [\"Family is not an important thing. It's everything.\"]\n",
    "#-----------------------\n",
    "# sw = stopwords.words(\"english\")\n",
    "# vect = CountVectorizer(stop_words=sw)\n",
    "#-----------------------\n",
    "vect = CountVectorizer(stop_words=[\"the\", \"a\", \"an\", \"is\", \"not\"])\n",
    "#-----------------------\n",
    "print(vect.fit_transform(text).toarray()) \n",
    "print(vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pressing-announcement",
   "metadata": {},
   "source": [
    "#### 불용언처리 (한글)\n",
    "* https://github.com/stopwords-iso/stopwords-ko"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "raised-snapshot",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['!', '\"', '$', '%', '&', \"'\", '(', ')', '*', '+']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords_ko = []\n",
    "f = open('./datasets/stopwords_ko.txt', mode='r', encoding='utf-8')\n",
    "for line in f:\n",
    "    line = line.rstrip(\"\\n\")\n",
    "    stopwords_ko.append(line)\n",
    "    \n",
    "stopwords_ko[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "talented-savage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 1 1]]\n",
      "{'나는': 1, '웃으며': 4, '문을': 3, '닫고': 2, '나갔다': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\it\\pythonproject2\\venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:383: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['가서', '같은', '것과', '결과에', '결론을', '관계가', '관련이', '그런', '그럼에도', '그렇게', '그에', '그치지', '김에', '까닭에', '낫다', '년도', '논하지', '누가', '다시', '달려', '대로', '대해', '되는', '되다', '되어', '들면', '들자면', '듯하다', '따르는', '따름이다', '따지지', '때가', '만은', '만이', '많은', '말하면', '말할것도', '몰라도', '몰랏다', '못하다', '미치다', '바꾸어서', '바꿔', '밖에', '방면으로', '보면', '보아', '부류의', '비길수', '비추어', '뿐만', '사람들', '상대적으로', '생각이다', '서술한바와같이', '쓰여', '아니다', '아니라', '안다', '안된다', '않고', '않기', '않는다면', '않다', '않다면', '않도록', '않으면', '알겠는가', '어쩔수', '없고', '없다', '예를', '외에', '요만한', '우에', '위에서', '이렇게', '이로', '이르다', '이와', '이유는', '인하여', '임에', '점에서', '정도에', '정도의', '종합한것과같이', '주저하지', '줄은', '지경이다', '틀림없다', '편이', '하고', '하기', '하기만', '하는', '하는것만', '하는것이', '하다', '하면', '하지', '한하다', '할수록', '함으로써', '해도', '해서는', '형식으로', '힘이'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "text = [\"나는 하하 웃으며 쿵 문을 닫고 나갔다.\"]\n",
    "#-----------------------\n",
    "# sw = stopwords.words(\"english\")\n",
    "# vect = CountVectorizer(stop_words=sw)\n",
    "#-----------------------\n",
    "vect = CountVectorizer(stop_words=stopwords_ko)\n",
    "#-----------------------\n",
    "print(vect.fit_transform(text).toarray()) \n",
    "print(vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "understood-oregon",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 코사인 유사도(Cosine Similarity)\n",
    "* <font color='red'>벡터의 크기가 아니라 방향(패턴)에 초점</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "joint-welcome",
   "metadata": {},
   "source": [
    "<img src='./img/img2.png' width=500><br>\n",
    "<img src='./img/img3.png' width=500><br>\n",
    "<img src='./img/img4.png' width=300>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "primary-expansion",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "finite-couple",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_sim(A, B):\n",
    "    return dot(A, B)/(norm(A)*norm(B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "sticky-firewall",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = np.array([0,1,1,1])\n",
    "doc2 = np.array([1,0,1,1])\n",
    "doc3 = np.array([2,0,2,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "orange-cruise",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666667\n",
      "0.6666666666666667\n",
      "1.0000000000000002\n"
     ]
    }
   ],
   "source": [
    "print(cos_sim(doc1, doc2)) \n",
    "print(cos_sim(doc1, doc3)) \n",
    "print(cos_sim(doc2, doc3)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "serial-responsibility",
   "metadata": {},
   "source": [
    "### [실습] 영화추천 시스템\n",
    "* ref : https://www.kaggle.com/rounakbanik/the-movies-dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "based-slovenia",
   "metadata": {},
   "source": [
    "### [실습] 지수 변동성 유사도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hydraulic-preview",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "union-spread",
   "metadata": {},
   "source": [
    "## 문서 단어 행렬(DTM, Document-Term Matrix)\n",
    "* 각 문서에서 등장한 단어의 빈도를 행렬의 값으로 표기해 서로 다른 문서들을 비교\n",
    "* 다수의 BoW : 각 문서에 대한 BoW를 하나의 행렬로 만든 것\n",
    "\n",
    "* <단점>\n",
    "    - 희소 표현(Sparse representation) : 단어 집합의 크기 == 벡터의 차원이 되고 대부분의 값이 0이 된다\n",
    "    - 단순 빈도 수 기반 접근 : '이다'와 같은 중요하지 않은 최빈도 단어로 문서를 연관지으면??\n",
    "    - <font color='red'> TF-IDF 필요 (DTM에 불용어와 중요한 단어에 대해서 가중치)</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annoying-satin",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "incorporated-scheduling",
   "metadata": {},
   "source": [
    "## 단어 빈도-역 문서 빈도(TF-IDF, Term Frequency-Inverse Document Frequency)\n",
    "* 우선 DTM을 만든 후, TF-IDF 가중치를 부여\n",
    "* 주로 문서의 유사도를 구하는 작업, 검색 시스템에서 검색 결과의 중요도를 정하는 작업, 문서 내에서 특정 단어의 중요도를 구하는 작업 등에 활용\n",
    "* TF-IDF = TF * IDF\n",
    "\n",
    "* 문서(d), 단어(t), 문서총개수(n)\n",
    "* <font color='red'> $tf(d,t)$ : 특정 문서 d에서의 특정 단어 t의 등장 횟수</font>\n",
    "* <font color='red'>  $df(t)$ : 특정 단어 t가 등장한 문서의 수 </font>\n",
    "* <font color='red'>  $idf(d, t) = log (\\frac{n}{1+df(t)})$ : df(t) 역수</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "portuguese-unemployment",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from math import log # IDF계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "important-allah",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['먹고', '노란', '좋아요', '바나나', '저는', '과일이', '길고', '사과', '싶은']\n"
     ]
    }
   ],
   "source": [
    "docs = [\n",
    "  '먹고 싶은 사과',\n",
    "  '먹고 싶은 바나나',\n",
    "  '길고 노란 바나나 바나나',\n",
    "  '저는 과일이 좋아요'\n",
    "] \n",
    "vocab = list(set(w for doc in docs for w in doc.split()))\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "silent-myrtle",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf(t, d): #DTM\n",
    "    return d.count(t)\n",
    "\n",
    "def idf(t):\n",
    "    df = 0\n",
    "    for doc in docs:\n",
    "        df += t in doc\n",
    "    return log(N/(df + 1))\n",
    "\n",
    "def tfidf(t, d):\n",
    "    return tf(t,d)* idf(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sealed-suspension",
   "metadata": {},
   "source": [
    "* TF (TDM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "reverse-pointer",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>먹고</th>\n",
       "      <th>노란</th>\n",
       "      <th>좋아요</th>\n",
       "      <th>바나나</th>\n",
       "      <th>저는</th>\n",
       "      <th>과일이</th>\n",
       "      <th>길고</th>\n",
       "      <th>사과</th>\n",
       "      <th>싶은</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   먹고  노란  좋아요  바나나  저는  과일이  길고  사과  싶은\n",
       "0   1   0    0    0   0    0   0   1   1\n",
       "1   1   0    0    1   0    0   0   0   1\n",
       "2   0   1    0    2   0    0   1   0   0\n",
       "3   0   0    1    0   1    1   0   0   0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = len(docs) # 총 문서의 수\n",
    "result = []\n",
    "for i in range(N):\n",
    "    result.append([])\n",
    "    d = docs[i]\n",
    "    for j in range(len(vocab)):\n",
    "        t = vocab[j]        \n",
    "        result[-1].append(tf(t, d))\n",
    "\n",
    "tf_ = pd.DataFrame(result, columns = vocab) # TDM\n",
    "tf_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reasonable-celtic",
   "metadata": {},
   "source": [
    "* IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "banned-satin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IDF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>먹고</th>\n",
       "      <td>0.287682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>노란</th>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>좋아요</th>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>바나나</th>\n",
       "      <td>0.287682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>저는</th>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>과일이</th>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>길고</th>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>사과</th>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>싶은</th>\n",
       "      <td>0.287682</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          IDF\n",
       "먹고   0.287682\n",
       "노란   0.693147\n",
       "좋아요  0.693147\n",
       "바나나  0.287682\n",
       "저는   0.693147\n",
       "과일이  0.693147\n",
       "길고   0.693147\n",
       "사과   0.693147\n",
       "싶은   0.287682"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = []\n",
    "for j in range(len(vocab)):\n",
    "    t = vocab[j]\n",
    "    result.append(idf(t))  # idf계산\n",
    "\n",
    "idf_ = pd.DataFrame(result, index = vocab, columns = [\"IDF\"])\n",
    "idf_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trying-newfoundland",
   "metadata": {},
   "source": [
    "* TF-IDF 행렬 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "regular-gnome",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>먹고</th>\n",
       "      <th>노란</th>\n",
       "      <th>좋아요</th>\n",
       "      <th>바나나</th>\n",
       "      <th>저는</th>\n",
       "      <th>과일이</th>\n",
       "      <th>길고</th>\n",
       "      <th>사과</th>\n",
       "      <th>싶은</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.287682</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.287682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.287682</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.287682</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.287682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.575364</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         먹고        노란       좋아요       바나나        저는       과일이        길고  \\\n",
       "0  0.287682  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.287682  0.000000  0.000000  0.287682  0.000000  0.000000  0.000000   \n",
       "2  0.000000  0.693147  0.000000  0.575364  0.000000  0.000000  0.693147   \n",
       "3  0.000000  0.000000  0.693147  0.000000  0.693147  0.693147  0.000000   \n",
       "\n",
       "         사과        싶은  \n",
       "0  0.693147  0.287682  \n",
       "1  0.000000  0.287682  \n",
       "2  0.000000  0.000000  \n",
       "3  0.000000  0.000000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = []\n",
    "for i in range(N):\n",
    "    result.append([])\n",
    "    d = docs[i]\n",
    "    for j in range(len(vocab)):\n",
    "        t = vocab[j]\n",
    "        result[-1].append(tfidf(t,d))\n",
    "\n",
    "tfidf_ = pd.DataFrame(result, columns = vocab)\n",
    "tfidf_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suited-museum",
   "metadata": {
    "tags": []
   },
   "source": [
    "### [실습] 사이킷런을 이용한 DTM과 TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rotary-sister",
   "metadata": {},
   "source": [
    "* 보편적 : TF-IDF 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "sensitive-database",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 1 1]\n",
      " [1 0 1 1]\n",
      " [2 0 2 2]]\n",
      "{'저는': 2, '사과': 1, '좋아요': 3, '바나나': 0}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "corpus = [\n",
    "    '저는 사과 좋아요',\n",
    "    '저는 바나나 좋아요',\n",
    "    '저는 바나나 좋아요 저는 바나나 좋아요',    \n",
    "]\n",
    "vector = CountVectorizer()\n",
    "print(vector.fit_transform(corpus).toarray())  # 코퍼스로부터 각 단어의 빈도 수 기록\n",
    "print(vector.vocabulary_)                      # 각 단어에 부여된 인덱스 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oriental-photograph",
   "metadata": {},
   "source": [
    "* TfidfVectorizer : TF-IDF 계산\n",
    "* (IDF의 로그항의 분자에 1을 더해주며, 로그항에 1을 더해주고, TF-IDF에 L2 정규화라는 방법으로 값을 조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "manual-orange",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'> \n",
      "   (0, 3)\t0.4532946552278861\n",
      "  (0, 1)\t0.7674945674619879\n",
      "  (0, 2)\t0.4532946552278861\n",
      "  (1, 0)\t0.6732546652684398\n",
      "  (1, 3)\t0.5228423068642596\n",
      "  (1, 2)\t0.5228423068642596\n",
      "  (2, 0)\t0.6732546652684398\n",
      "  (2, 3)\t0.5228423068642596\n",
      "  (2, 2)\t0.5228423068642596\n",
      "[[0.         0.76749457 0.45329466 0.45329466]\n",
      " [0.67325467 0.         0.52284231 0.52284231]\n",
      " [0.67325467 0.         0.52284231 0.52284231]]\n",
      "{'저는': 2, '사과': 1, '좋아요': 3, '바나나': 0}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "corpus = [\n",
    "    '저는 사과 좋아요',\n",
    "    '저는 바나나 좋아요',\n",
    "    '저는 바나나 좋아요 저는 바나나 좋아요',    \n",
    "]\n",
    "tfidfv = TfidfVectorizer()\n",
    "corpus_v = tfidfv.fit_transform(corpus)\n",
    "print(f'{type(corpus_v)} \\n {corpus_v}')\n",
    "print(corpus_v.toarray())\n",
    "print(tfidfv.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statutory-plenty",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acute-latex",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "intended-bearing",
   "metadata": {},
   "source": [
    "# 군집간 유사도(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "short-differential",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "naked-lexington",
   "metadata": {},
   "source": [
    "### [실습] 주가 군집 유사도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ancient-local",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "clean-afghanistan",
   "metadata": {},
   "source": [
    "### [실습] K-means를 활용한 Document Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exempt-investing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "homeless-hybrid",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
